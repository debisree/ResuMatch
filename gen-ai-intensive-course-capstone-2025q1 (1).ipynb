{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f3ebe3",
   "metadata": {
    "papermill": {
     "duration": 0.00791,
     "end_time": "2025-04-21T05:36:01.193653",
     "exception": false,
     "start_time": "2025-04-21T05:36:01.185743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìÑ‚ú® ResuMatch: A RAG-Powered Resume Tailoring Assistant\n",
    "> *An agentic GenAI system that analyzes, matches, and rewrites resumes for any job ‚Äî intelligently and interactively.*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### ‚úÖ Phase 1: MVP with Single Job Description (Recommended to Start)\n",
    "üìÑ Upload Resume (PDF)\n",
    "\n",
    "üîó Paste Job Description URL or text\n",
    "\n",
    "üß† Extract and analyze JD\n",
    "\n",
    "üìä Compute match score\n",
    "\n",
    "‚úçÔ∏è Tailor resume \n",
    "\n",
    "üí¨ Chat-based refinement (user feedback loop)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "üìå This notebook defines a complete Retrieval-Augmented Generation (RAG) pipeline for intelligent resume matching. It uses LangChain agents, Gemini (Google GenAI) to:\n",
    "- Extract and analyze resumes\n",
    "- Compare with job descriptions\n",
    "- Identify skill gaps\n",
    "- Interact with users to fill in missing skills\n",
    "- Generate a tailored resume \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### üîÅ Future Scope: Scrape & Rank Top 10 Jobs (LinkedIn, etc.)\n",
    "\n",
    "* Automatically scrape multiple jobs (via scraping or API)\n",
    "\n",
    "* Rank them by match score\n",
    "\n",
    "* Present a ranked list with links, highlights, and an automatic ‚ÄúApply‚Äù buttons.\n",
    "\n",
    "* The entire agentic workflow should be automated and will be deployed with an U/I (eg. gradio)\n",
    "\n",
    "* Generate a cover letter also to highlight the credential with a personal touch. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f245d46",
   "metadata": {
    "papermill": {
     "duration": 0.005983,
     "end_time": "2025-04-21T05:36:01.206320",
     "exception": false,
     "start_time": "2025-04-21T05:36:01.200337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###  üìä Visual Workflow Overview \n",
    "\n",
    "\n",
    "1. Resume Upload\n",
    "\n",
    "   \n",
    "   ‚îî‚îÄ‚îÄ Extract text from PDF using PyMuPDF via LangChain agent\n",
    "\n",
    "   \n",
    "\n",
    "2. Job Description Input\n",
    "\n",
    "   \n",
    "   ‚îî‚îÄ‚îÄ Paste or upload JD, cleaned and processed\n",
    "\n",
    "   \n",
    "\n",
    "3. Semantic Match Scoring\n",
    "\n",
    "   \n",
    "   ‚îî‚îÄ‚îÄ Gemini prompt-based scoring (0‚Äì100) via LangChain tool\n",
    "\n",
    "   \n",
    "\n",
    "4. Skill Gap Analysis\n",
    "\n",
    "   \n",
    "   ‚îî‚îÄ‚îÄ Gemini identifies 8‚Äì10 missing skills not present in the resume\n",
    "\n",
    "5. Interactive Feedback Agent\n",
    "\n",
    "    \n",
    "   ‚îî‚îÄ‚îÄ User engages with each missing skill via chatbot interface\n",
    "       ‚Üí Describes experience or opts to skip\n",
    "\n",
    "   \n",
    "\n",
    "6. Resume Rewriting Agent\n",
    "\n",
    "    \n",
    "   ‚îî‚îÄ‚îÄ Gemini re-generates the resume using:\n",
    "       - Original resume text\n",
    "       - Job description\n",
    "       - User feedback (RAG prompt)\n",
    "       \n",
    "\n",
    "7. Output: Tailored Resume\n",
    "    \n",
    "   ‚îî‚îÄ‚îÄ Save as:\n",
    "       - .docx (with formatting, bullets, bold headers)\n",
    "       - .tex (moderncv LaTeX format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a8e8c3",
   "metadata": {
    "papermill": {
     "duration": 0.007368,
     "end_time": "2025-04-21T05:36:01.219933",
     "exception": false,
     "start_time": "2025-04-21T05:36:01.212565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Gen AI Intensive Course Capstone 2025Q1\n",
    "\n",
    "\n",
    "### NoteBook by Debisree Ray\n",
    "\n",
    "April 2025\n",
    "\n",
    "https://www.kaggle.com/competitions/gen-ai-intensive-course-capstone-2025q1\n",
    "\n",
    "This notebook is the capstone project work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2abf987",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-21T05:36:01.234956Z",
     "iopub.status.busy": "2025-04-21T05:36:01.234560Z",
     "iopub.status.idle": "2025-04-21T05:36:03.235661Z",
     "shell.execute_reply": "2025-04-21T05:36:03.234432Z"
    },
    "papermill": {
     "duration": 2.011279,
     "end_time": "2025-04-21T05:36:03.237174",
     "exception": false,
     "start_time": "2025-04-21T05:36:01.225895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/my-resume/DR.pdf\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67b17458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:36:03.251179Z",
     "iopub.status.busy": "2025-04-21T05:36:03.250721Z",
     "iopub.status.idle": "2025-04-21T05:36:09.655221Z",
     "shell.execute_reply": "2025-04-21T05:36:09.653890Z"
    },
    "papermill": {
     "duration": 6.413726,
     "end_time": "2025-04-21T05:36:09.657308",
     "exception": false,
     "start_time": "2025-04-21T05:36:03.243582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#!pip uninstall -qqy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n",
    "!pip install -U -q \"google-genai==1.7.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e716418",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:36:09.672175Z",
     "iopub.status.busy": "2025-04-21T05:36:09.671297Z",
     "iopub.status.idle": "2025-04-21T05:36:30.221019Z",
     "shell.execute_reply": "2025-04-21T05:36:30.219784Z"
    },
    "papermill": {
     "duration": 20.559448,
     "end_time": "2025-04-21T05:36:30.223201",
     "exception": false,
     "start_time": "2025-04-21T05:36:09.663753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51ac2081",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:36:30.239822Z",
     "iopub.status.busy": "2025-04-21T05:36:30.238767Z",
     "iopub.status.idle": "2025-04-21T05:36:36.220228Z",
     "shell.execute_reply": "2025-04-21T05:36:36.218991Z"
    },
    "papermill": {
     "duration": 5.991761,
     "end_time": "2025-04-21T05:36:36.222009",
     "exception": false,
     "start_time": "2025-04-21T05:36:30.230248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\r\n",
      "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\r\n",
      "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\r\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\r\n",
      "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (1.34.1)\r\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\r\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\r\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (3.20.3)\r\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.3)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.1)\r\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.67.0)\r\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\r\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\r\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\r\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.1)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\r\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\r\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.48.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\r\n",
      "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: PyMuPDF\r\n",
      "Successfully installed PyMuPDF-1.25.5\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install PyMuPDF google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226d4a05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:36:36.238389Z",
     "iopub.status.busy": "2025-04-21T05:36:36.237528Z",
     "iopub.status.idle": "2025-04-21T05:36:40.218607Z",
     "shell.execute_reply": "2025-04-21T05:36:40.217339Z"
    },
    "papermill": {
     "duration": 3.9913,
     "end_time": "2025-04-21T05:36:40.220557",
     "exception": false,
     "start_time": "2025-04-21T05:36:36.229257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\r\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\r\n",
      "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.1)\r\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: python-docx\r\n",
      "Successfully installed python-docx-1.1.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ae598d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:36:40.236751Z",
     "iopub.status.busy": "2025-04-21T05:36:40.236394Z",
     "iopub.status.idle": "2025-04-21T05:36:46.501800Z",
     "shell.execute_reply": "2025-04-21T05:36:46.500643Z"
    },
    "papermill": {
     "duration": 6.275476,
     "end_time": "2025-04-21T05:36:46.503549",
     "exception": false,
     "start_time": "2025-04-21T05:36:40.228073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fpdf\r\n",
      "  Downloading fpdf-1.7.2.tar.gz (39 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Building wheels for collected packages: fpdf\r\n",
      "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=9357faff8f5a4bd644fe25849a059b8de035c11ad0968ba53c675e5c332faf0c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\r\n",
      "Successfully built fpdf\r\n",
      "Installing collected packages: fpdf\r\n",
      "Successfully installed fpdf-1.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9bc8b5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:36:46.520984Z",
     "iopub.status.busy": "2025-04-21T05:36:46.520262Z",
     "iopub.status.idle": "2025-04-21T05:36:57.493018Z",
     "shell.execute_reply": "2025-04-21T05:36:57.491952Z"
    },
    "papermill": {
     "duration": 10.983569,
     "end_time": "2025-04-21T05:36:57.494661",
     "exception": false,
     "start_time": "2025-04-21T05:36:46.511092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\r\n",
      "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\r\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\r\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\r\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\r\n",
      "Collecting ffmpy (from gradio)\r\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting gradio-client==1.8.0 (from gradio)\r\n",
      "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\r\n",
      "Collecting groovy~=0.1 (from gradio)\r\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\r\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\r\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\r\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\r\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.3)\r\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\r\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\r\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\r\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\r\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\r\n",
      "Collecting ruff>=0.9.3 (from gradio)\r\n",
      "  Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\r\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\r\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Collecting semantic-version~=2.0 (from gradio)\r\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\r\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\r\n",
      "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\r\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\r\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\r\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\r\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\r\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (14.2)\r\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\r\n",
      "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\r\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\r\n",
      "Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\r\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\r\n",
      "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\r\n",
      "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\r\n",
      "Installing collected packages: uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\r\n",
      "Successfully installed fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 python-multipart-0.0.20 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c8a6a63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:36:57.516214Z",
     "iopub.status.busy": "2025-04-21T05:36:57.515866Z",
     "iopub.status.idle": "2025-04-21T05:37:40.761772Z",
     "shell.execute_reply": "2025-04-21T05:37:40.760784Z"
    },
    "papermill": {
     "duration": 43.266961,
     "end_time": "2025-04-21T05:37:40.771745",
     "exception": false,
     "start_time": "2025-04-21T05:36:57.504784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 05:37:20.295341: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745213840.572146      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745213840.644210      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "import os\n",
    "\n",
    "#from selenium import webdriver\n",
    "#from selenium.webdriver.chrome.service import Service\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "#from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from fpdf import FPDF\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import re\n",
    "import gradio as gr\n",
    "\n",
    "#import google.generativeai as genai\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "from pprint import pprint  # optional, for prettier output\n",
    "from IPython.display import HTML, Markdown, display\n",
    "\n",
    "genai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c6d825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:37:40.793912Z",
     "iopub.status.busy": "2025-04-21T05:37:40.793008Z",
     "iopub.status.idle": "2025-04-21T05:37:40.959842Z",
     "shell.execute_reply": "2025-04-21T05:37:40.958849Z"
    },
    "papermill": {
     "duration": 0.179569,
     "end_time": "2025-04-21T05:37:40.961354",
     "exception": false,
     "start_time": "2025-04-21T05:37:40.781785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "genai.models.Models.generate_content = retry.Retry(\n",
    "    predicate=is_retriable)(genai.models.Models.generate_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e75acc1",
   "metadata": {
    "papermill": {
     "duration": 0.009524,
     "end_time": "2025-04-21T05:37:40.981324",
     "exception": false,
     "start_time": "2025-04-21T05:37:40.971800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Secret API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9969dcaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:37:41.002335Z",
     "iopub.status.busy": "2025-04-21T05:37:41.001983Z",
     "iopub.status.idle": "2025-04-21T05:37:41.167640Z",
     "shell.execute_reply": "2025-04-21T05:37:41.166548Z"
    },
    "papermill": {
     "duration": 0.17864,
     "end_time": "2025-04-21T05:37:41.169746",
     "exception": false,
     "start_time": "2025-04-21T05:37:40.991106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0708a5e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:37:41.192496Z",
     "iopub.status.busy": "2025-04-21T05:37:41.192066Z",
     "iopub.status.idle": "2025-04-21T05:37:41.320286Z",
     "shell.execute_reply": "2025-04-21T05:37:41.319255Z"
    },
    "papermill": {
     "duration": 0.141896,
     "end_time": "2025-04-21T05:37:41.322312",
     "exception": false,
     "start_time": "2025-04-21T05:37:41.180416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c5967e",
   "metadata": {
    "papermill": {
     "duration": 0.010375,
     "end_time": "2025-04-21T05:37:41.343555",
     "exception": false,
     "start_time": "2025-04-21T05:37:41.333180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚úÖ Step 1: Resume Parser (PDF to Text)\n",
    "\n",
    "The goal is to take the resume in pdf and convert that in a more usable format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d404664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:37:41.366531Z",
     "iopub.status.busy": "2025-04-21T05:37:41.366107Z",
     "iopub.status.idle": "2025-04-21T05:37:41.428461Z",
     "shell.execute_reply": "2025-04-21T05:37:41.427471Z"
    },
    "papermill": {
     "duration": 0.076396,
     "end_time": "2025-04-21T05:37:41.430533",
     "exception": false,
     "start_time": "2025-04-21T05:37:41.354137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === üìÑ Resume Extractor ===\n",
    "@tool\n",
    "def resume_extraction_agent(file_path: str) -> str:\n",
    "    \"\"\"Reads a PDF resume from the given path and returns the extracted text.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        doc = fitz.open(stream=f.read(), filetype=\"pdf\")\n",
    "        text = \"\".join([page.get_text() for page in doc])\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "resume_text = resume_extraction_agent.invoke({'file_path': '/kaggle/input/my-resume/DR.pdf'} )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127cbc47",
   "metadata": {
    "papermill": {
     "duration": 0.010213,
     "end_time": "2025-04-21T05:37:41.451816",
     "exception": false,
     "start_time": "2025-04-21T05:37:41.441603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### A summary generator \n",
    "\n",
    "We don't actually need it, directly for the project purpose - however, it can be useful.\n",
    "\n",
    "It can be used for any quick reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72c147f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:37:41.582254Z",
     "iopub.status.busy": "2025-04-21T05:37:41.581799Z",
     "iopub.status.idle": "2025-04-21T05:37:44.351587Z",
     "shell.execute_reply": "2025-04-21T05:37:44.350503Z"
    },
    "papermill": {
     "duration": 2.78411,
     "end_time": "2025-04-21T05:37:44.353294",
     "exception": false,
     "start_time": "2025-04-21T05:37:41.569184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a summary of the resume, extracting the information you requested:\n",
      "\n",
      "*   **Full Name:** Debisree Ray\n",
      "*   **Highest Degree:** Ph.D.\n",
      "*   **Email:** debisreer@gmail.com\n",
      "*   **Phone:** 662-694-1319\n",
      "*   **Top 10 Skills:**\n",
      "    1.  Data Wrangling\n",
      "    2.  Exploratory Data Analysis (EDA)\n",
      "    3.  Data Visualization\n",
      "    4.  Machine Learning (Regression/Classification)\n",
      "    5.  Deep Learning\n",
      "    6.  Web Application Development (Python-Flask)\n",
      "    7.  MLOps (CI/CD Pipelines)\n",
      "    8.  Statistical Data Analytics\n",
      "    9.  Scientific Computing\n",
      "    10. Technical Writing\n",
      "*   **Tech Stack:** Python, Flask, SQL, Azure, Databricks, Anaconda/Jupyter, Pandas, NumPy, Seaborn, SciPy, Matplotlib, Plotly, MLflow, Azure DevOps, Unity-3D. Fortran, R, LaTeX, Mathematica, MATLAB, XMRACE, GnuPlot\n",
      "*   **Preferred Job Titles:** Data Scientist\n",
      "*   **Years of Experience:** 6+ years (Post Ph.D. experience based on dates provided, not including teaching/research assistant roles)\n",
      "*   **Last Three Job Roles:**\n",
      "    *   Data Scientist, Big River Steel LLC (a US Steel Company) (2021 - Present)\n",
      "    *   Global Scholar / Data Analyst intern, Prescouter (2019 - 2019)\n",
      "    *   Postdoctoral Associate, Institute of Systems Engineering Research (ISER), Mississippi State University (2017 - 2019)\n",
      "*   **Education Summary:**\n",
      "    *   Ph.D., Engineering (Low-Energy Computational Nuclear Structure Physics) - Mississippi State University (2011-2017)\n",
      "    *   M.Sc., Physics - University of Calcutta (2008-2010)\n",
      "    *   B.Sc. (Honors), Physics (Major), Electronics and Mathematics (Minor) (2004-2008)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === üìÑ Resume summarizer ===\n",
    "\n",
    "def summarize_resume_with_gemini(resume_text):\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert resume summarizer. Extract the following from the resume:\n",
    "    - Full name\n",
    "    _ Highest Degree\n",
    "    - Email (if available)\n",
    "    - Phone (if available)\n",
    "    - Top 10 skills\n",
    "    _ Tech Stack\n",
    "    - Preferred job titles\n",
    "    - Years of experience\n",
    "    - Last three job roles with company and duration\n",
    "    - Education summary\n",
    "\n",
    "    Resume:\n",
    "    {resume_text}\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents= prompt)\n",
    "\n",
    " \n",
    "    return response.text\n",
    "\n",
    "summary = summarize_resume_with_gemini(resume_text)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4014c558",
   "metadata": {
    "papermill": {
     "duration": 0.010439,
     "end_time": "2025-04-21T05:37:44.374666",
     "exception": false,
     "start_time": "2025-04-21T05:37:44.364227",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚úÖ Step 2: Job Description from Linkedin\n",
    "\n",
    "The goal is to take the JD convert that in a more usable format. \n",
    "\n",
    "Linkedin does not provide publicly available API. To begin with we are manually copying and pasting one particular job description that the user is interested in. \n",
    "\n",
    "We can take a screen-shot as well and retreive from the image. However, this has not done here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b0b8fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:37:44.398063Z",
     "iopub.status.busy": "2025-04-21T05:37:44.397617Z",
     "iopub.status.idle": "2025-04-21T05:37:44.411622Z",
     "shell.execute_reply": "2025-04-21T05:37:44.410358Z"
    },
    "papermill": {
     "duration": 0.028165,
     "end_time": "2025-04-21T05:37:44.413355",
     "exception": false,
     "start_time": "2025-04-21T05:37:44.385190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === üßæ Job Description Loader ===\n",
    "\n",
    "@tool\n",
    "def jd_loader_agent(jd_text) -> str:\n",
    "    \"\"\"Cleans and returns job description text from raw pasted input.\"\"\"\n",
    "    return jd_text.strip()\n",
    "\n",
    "jd_text = jd_loader_agent.invoke({\"jd_text\":\"\"\"\" About the job Position Summary\n",
    "\n",
    "What you'll do\n",
    "\n",
    "We are looking for a Senior Data Scientist to join our science team and develop state-of-the-art models to power Product Search and Recommendation across Walmart‚Äôs multiple international markets. Our mission is to provide our customers with the most delightful user experience throughout their online shopping journey with us. We create powerful AI and ML powered solutions for highly intricate real-world problems. You will be working on these industry-defining problems and have the opportunity to push the frontiers of Search & Recommendation Science by advancing areas including AI, ML, NLP, Optimization, Algorithm and Customer-facing large system and service designs.\n",
    "\n",
    "What You Will Do\n",
    "\n",
    "Bring in bleeding-edge academic research and industry practices and demonstrate originality and creativity in developing novel solutions for Search or Recommendation Systems.\n",
    "Partner with other data scientists, engineers and product managers to design, train, test and deploy machine learning models.\n",
    "Work on projects with substantial ambiguity and translate business and engineering requirements to identify and define a clear roadmap to deliver the ML models.\n",
    "Perform rigorous offline and A/B testing of your models and communicate your findings to technical and non-technical stakeholders, both verbally and through written communications.\n",
    "You will help maintain models, improve them as needed to bring in cutting-edge research, within a highly scalable infrastructure.\n",
    "You will also help new data scientist‚Äôs onboarding and mentorship.\n",
    "You are strongly encouraged to publish your research and novel findings in internal and external research and industry conferences and journals, and file patent applications.\n",
    "\n",
    "What You Will Bring\n",
    "\n",
    "Have a MS/PhD in relevant technical degree (preferably Computer Science, Machine Learning, Operations Research, Applied Mathematics, Statistics, Engineering etc.) with 3+ years of relevant work experience.\n",
    "Must have a deep background in NLP, Search Science, Recommendation Systems, Machine Learning, Deep Learning, Optimization, Algorithm and Software development.\n",
    "It is a bonus to have prior knowledge of Search/Recommendation Systems related technology and Generative AI.\n",
    "Sound knowledge of Python, SQL, PySpark, Machine Learning Libraries, Big Data processing systems in cloud environment is expected.\n",
    "A track record of building ML models or delivering impactful customer-facing products.\n",
    "Experience of publications in peer-reviewed conferences and journals or patent filings.\n",
    "\n",
    "At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.\n",
    "\n",
    "\n",
    "\n",
    "You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.\n",
    "\n",
    "\n",
    "\n",
    "For information about PTO, see https://one.walmart.com/notices.\n",
    "\n",
    "\n",
    "Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.\n",
    "\n",
    "\n",
    "\n",
    "Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.\n",
    "\n",
    "\n",
    "\n",
    "For Information About Benefits And Eligibility, See One.Walmart.\n",
    "\n",
    "\n",
    "\n",
    "The annual salary range for this position is $117,000.00-$234,000.00\n",
    "\n",
    "\n",
    "Additional Compensation Includes Annual Or Quarterly Performance Bonuses.\n",
    "\n",
    "\n",
    "Additional Compensation For Certain Positions May Also Include\n",
    "\n",
    "\n",
    " Stock\n",
    "\n",
    "Minimum Qualifications...\n",
    "\n",
    "Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications. \n",
    "\n",
    "Option 1- Bachelor‚Äôs degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master‚Äôs degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.\n",
    "\n",
    "Preferred Qualifications...\n",
    "\n",
    "Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\n",
    "\n",
    "Data science, machine learning, optimization models, Master‚Äôs degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart‚Äôs accessibility standards and guidelines for supporting an inclusive culture.\n",
    "\n",
    "Primary Location...\n",
    "\n",
    "680 West California Avenue, Sunnyvale, CA 94086-4834, United States of America \"\"\"})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08817aa0",
   "metadata": {
    "papermill": {
     "duration": 0.0106,
     "end_time": "2025-04-21T05:37:44.435335",
     "exception": false,
     "start_time": "2025-04-21T05:37:44.424735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚úÖ Step 3: Comparing the resume text and JD to generate a similarity score\n",
    "\n",
    "### The goal is to analyze how well the resume is aligned with the JD. \n",
    "\n",
    "\n",
    "\n",
    "LangChain Agent: Match Score Evaluator\n",
    "\n",
    "**What is a LangChain Agent?**\n",
    "  \n",
    "A LangChain agent is a smart reasoning system that can decide which tools or prompts\n",
    "to use dynamically based on the input. It acts like a smart assistant that chains multiple\n",
    "reasoning steps together (e.g., parse > search > score > refine). In this case, we wrap the matching score process into an agent that:\n",
    "- Accepts the resume and job description\n",
    "- Calls Gemini to produce a numeric match score\n",
    "- Optionally returns reasoning/explanation as a separate step\n",
    "\n",
    "\n",
    "This makes our RAG engine modular and extendable to tool-based pipelines (e.g., memory, retrieval, editing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a891009b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:37:44.459455Z",
     "iopub.status.busy": "2025-04-21T05:37:44.458586Z",
     "iopub.status.idle": "2025-04-21T05:37:44.963387Z",
     "shell.execute_reply": "2025-04-21T05:37:44.962423Z"
    },
    "papermill": {
     "duration": 0.518697,
     "end_time": "2025-04-21T05:37:44.964901",
     "exception": false,
     "start_time": "2025-04-21T05:37:44.446204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "@tool\n",
    "def match_score_agent(resume_text: str, jd_text: str) -> float:\n",
    "    \"\"\"Uses Gemini to return a 0‚Äì100 numeric score indicating how well the resume matches the job description.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are an expert AI evaluator. Score how well the following resume matches the job description on a scale of 0 to 100.\n",
    "Return only the numeric score. Do not include explanation.\n",
    "\n",
    "Resume:\n",
    "{resume_text}\n",
    "\n",
    "Job Description:\n",
    "{jd_text}\n",
    "\"\"\"\n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents= prompt)\n",
    "    try:\n",
    "        return round(float(response.text.strip()), 2)\n",
    "    except ValueError:\n",
    "        print(\"‚ö†Ô∏è Unable to parse score from model output:\", response.text)\n",
    "        return None\n",
    "\n",
    "\n",
    "score= match_score_agent.invoke({'resume_text': 'resume_text', 'jd_text': 'jd_text'} )\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb72106",
   "metadata": {
    "papermill": {
     "duration": 0.010194,
     "end_time": "2025-04-21T05:37:44.986549",
     "exception": false,
     "start_time": "2025-04-21T05:37:44.976355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚úÖ Step 4: Skill Gap Analyzer - LangChain Agentic Skill Analyzer\n",
    "\n",
    "I want to give the user point-wise input, the gap in the skills between the resume and the JD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea1f27e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:37:45.009311Z",
     "iopub.status.busy": "2025-04-21T05:37:45.008930Z",
     "iopub.status.idle": "2025-04-21T05:37:47.034645Z",
     "shell.execute_reply": "2025-04-21T05:37:47.033580Z"
    },
    "papermill": {
     "duration": 2.039211,
     "end_time": "2025-04-21T05:37:47.036271",
     "exception": false,
     "start_time": "2025-04-21T05:37:44.997060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ‚ùå Missing Skills or Keywords\n",
       "\n",
       "Here's a comparison of the resume and job description, highlighting the missing skills:\n",
       "\n",
       "1.  NLP: The resume mentions general data science and machine learning but lacks explicit mention of Natural Language Processing experience, a core requirement for the position.\n",
       "2.  Search Science: While the resume mentions experience building ML models, it does not demonstrate specific experience in search science, which is a primary focus of the role.\n",
       "3.  Recommendation Systems: Similar to search science, the resume lacks specific experience in building or deploying recommendation systems.\n",
       "4.  Generative AI: The job description mentions prior knowledge of Generative AI as a bonus, and this is not mentioned in the resume.\n",
       "5.  PySpark: Although the resume mentions Python, SQL, and general data science tools, it does not explicitly mention PySpark, which is listed as an expected skill.\n",
       "6.  Experience with customer-facing products: The job description requires a track record of building ML models or delivering impactful customer-facing products, which the resume does not highlight adequately. The resume mainly mentions internal dashboards.\n",
       "7.  Experience with large systems: The job description mentions working in \"customer-facing large system and service designs,\" while the resume lacks explicit experience or contributions to large-scale systems.\n",
       "8.  Accessibility knowledge (WCAG 2.2 AA): The job description mentions preferred qualifications in creating inclusive digital experiences and knowledge of Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, which are not mentioned in the resume."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@tool\n",
    "def missing_skills_agent(resume_text: str, jd_text: str) -> str:\n",
    "    \"\"\"Uses Gemini to identify missing skills from the job description compared to the resume.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant that compares job descriptions to resumes.\n",
    "\n",
    "Resume:\n",
    "{resume_text}\n",
    "\n",
    "Job Description:\n",
    "{jd_text}\n",
    "\n",
    "Identify the most important 8‚Äì10 skills or qualifications from the job description that are clearly missing from the resume.\n",
    "\n",
    "For each point:\n",
    "1. Start with a numbered index (1., 2., etc.)\n",
    "2. Clearly name the missing skill\n",
    "3. Provide a short but specific explanation\n",
    "4. Format the entire output exactly as:\n",
    "\n",
    "1. Skill Name: Explanation\n",
    "\n",
    "Each point MUST begin with the number and a dot, followed by the skill name, then a colon, and the explanation in one paragraph. Be consistent across runs.\n",
    "\"\"\"\n",
    "   \n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents= prompt)\n",
    "    return response.text.strip()\n",
    "   \n",
    "\n",
    "# Run skill matching and render the markdown\n",
    "\n",
    "\n",
    "missing_skills = missing_skills_agent.invoke({\"resume_text\": resume_text, \"jd_text\": jd_text})\n",
    "display(Markdown(f\"### ‚ùå Missing Skills or Keywords\\n\\n{missing_skills}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568259fd",
   "metadata": {
    "papermill": {
     "duration": 0.011745,
     "end_time": "2025-04-21T05:37:47.059184",
     "exception": false,
     "start_time": "2025-04-21T05:37:47.047439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚úÖ Step 5: User Feedback Agent- A conversational bot to collect user's input regarding all missing points\n",
    "\n",
    "As the workflow pointed out all skill gaps (between the resume & the JD), this is a conversation between with the agent and the user to get more clarity about the 'gaps'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad5f83c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:37:47.083439Z",
     "iopub.status.busy": "2025-04-21T05:37:47.082395Z",
     "iopub.status.idle": "2025-04-21T05:37:47.095910Z",
     "shell.execute_reply": "2025-04-21T05:37:47.095053Z"
    },
    "papermill": {
     "duration": 0.027046,
     "end_time": "2025-04-21T05:37:47.097398",
     "exception": false,
     "start_time": "2025-04-21T05:37:47.070352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def user_feedback_agent(missing_skills: str) -> list:\n",
    "    \"\"\"Conversational Gemini agent that collects user feedback naturally for each missing skill.\"\"\"\n",
    "    print(\"üëã Hello! Let's work together to refine your resume based on the missing skills I found.\")\n",
    "    print(\"üí¨ For each skill, you can respond freely ‚Äî no need for yes/no. Just tell me how you'd like to represent your experience.\")\n",
    "    print(\"‚úÖ Type 'pass' to skip or 'end' to finish anytime.\")\n",
    "\n",
    "    feedback_list = []\n",
    "    skills = re.findall(r\"\\d+\\.\\s+(.*?):\\s+(.*?)(?=\\n\\d+\\.\\s|\\Z)\", missing_skills, re.DOTALL)\n",
    "\n",
    "    if not skills:\n",
    "        print(\"‚ö†Ô∏è No skills parsed from the input. Please check formatting.\")\n",
    "        return feedback_list\n",
    "\n",
    "    for i, (skill, explanation) in enumerate(skills, 1):\n",
    "        print(f\"\\nüîπ {i}. {skill.strip()}\\nüìé {explanation.strip()}\")\n",
    "        response = input(\"üó£Ô∏è How would you describe your experience for this skill? (or type 'pass'/'end'): \").strip()\n",
    "\n",
    "        if response.lower() == 'end':\n",
    "            print(\"üõë Ending the session.\")\n",
    "            break\n",
    "        elif response.lower() == 'pass' or not response:\n",
    "            feedback_list.append((skill.strip(), None))\n",
    "        else:\n",
    "            feedback_list.append((skill.strip(), response))\n",
    "\n",
    "    print(\"‚úÖ Thanks! Your responses are saved.\")\n",
    "    return feedback_list\n",
    "\n",
    "# Fake feedback for auto submission mode\n",
    "def simulate_feedback(skills):\n",
    "    return [(skill, \"Simulated experience for submission.\") for skill in skills]\n",
    "\n",
    "\n",
    "is_kaggle = os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") == \"Batch\"\n",
    "if is_kaggle:\n",
    "    # Extract skill names from parsed missing_skills_agent\n",
    "    skills = [\"no\", \"yes\", 'yes', 'yes', 'yes', 'I have never worked with external clients. however, our stakeholders are interanl clients. i havebeen delivering Machine Learning based products.', \"Most of my publications are in computational physics.\", \"No\"]  # hardcoded or parsed\n",
    "    feedback_list = simulate_feedback(skills)\n",
    "else:\n",
    "    feedback_list = user_feedback_agent.invoke({\"missing_skills\": missing_skills})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa50c4a",
   "metadata": {
    "papermill": {
     "duration": 0.010264,
     "end_time": "2025-04-21T05:37:47.118559",
     "exception": false,
     "start_time": "2025-04-21T05:37:47.108295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚úÖ Step 6: Tailored Resume Generator \n",
    "\n",
    "The final step is to generate a tailored and polished resume - starting from the original resume. The focus should be to align the resume towards the JD, where as the user feedback needs to be taken into account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9978cab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:37:47.141594Z",
     "iopub.status.busy": "2025-04-21T05:37:47.140847Z",
     "iopub.status.idle": "2025-04-21T05:37:52.682055Z",
     "shell.execute_reply": "2025-04-21T05:37:52.681001Z"
    },
    "papermill": {
     "duration": 5.555015,
     "end_time": "2025-04-21T05:37:52.684087",
     "exception": false,
     "start_time": "2025-04-21T05:37:47.129072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resume saved as: AI_Gen_Resume.docx\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def generate_final_resume_agent(resume_text: str, jd_text: str, user_feedback: list) -> float:\n",
    "    \"\"\"Uses Gemini with RAG-style prompt to generate a polished final resume and saves it as a DOCX file.\"\"\"\n",
    "    \n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert resume rewriting agent. Rewrite the resume to align with the job description.\n",
    "    \n",
    "    Return content in the following structure only:\n",
    "    1. A centered bold heading with name: Debisree Ray, PhD\n",
    "    2. A **single line** contact block: üìç Memphis, TN | ‚úâÔ∏è debisreer@gmail.com | ‚òéÔ∏è 662-694-1319 | üîó LinkedIn: https://www.linkedin.com/in/debisree-ray-ph-d-82241355/ | üß† Kaggle: https://www.kaggle.com/debisree | üíª GitHub: https://github.com/debisree\n",
    "    3. Section: SUMMARY ‚Äî short overview of profile\n",
    "    4. Section: SKILLS ‚Äî key skills\n",
    "    5. Section: WORK EXPERIENCE ‚Äî include job title, company, and bullet points\n",
    "    6. Section: EDUCATION ‚Äî list degrees\n",
    "    7. Section: PROJECTS ‚Äî if applicable\n",
    "    8. Section: LEADERSHIP & VOLUNTEERING ‚Äî include relevant experience\n",
    "    \n",
    "    Use bold headings, bullet points, and concise language. Do NOT include labels like 'Resume:', 'Job Description:', or explanations. Just return the resume content below.\n",
    "    \n",
    "    Resume:\n",
    "    {resume_text}\n",
    "\n",
    "    Job Description:\n",
    "    {jd_text}\n",
    "    \n",
    "    Skills/Feedback to integrate:\n",
    "    {feedback_list}\n",
    "    \"\"\"\n",
    "\n",
    " \n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents= prompt)\n",
    "    final_resume = response.text.strip()\n",
    "\n",
    "    doc = Document()\n",
    "    section_titles = [\"SUMMARY\", \"SKILLS\", \"WORK EXPERIENCE\", \"EDUCATION\", \"PROJECTS\", \"LEADERSHIP & VOLUNTEERING\"]\n",
    "\n",
    "    for i, line in enumerate(final_resume.splitlines()):\n",
    "        line = line.strip()\n",
    "        if i == 0:\n",
    "            para = doc.add_paragraph()\n",
    "            para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "            run = para.add_run(line)\n",
    "            run.bold = True\n",
    "            run.font.size = Pt(16)\n",
    "        elif line.startswith(\"üìç\") or line.startswith(\"‚úâÔ∏è\") or \"linkedin.com\" in line:\n",
    "            para = doc.add_paragraph()\n",
    "            para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "            run = para.add_run(line)\n",
    "            run.font.size = Pt(10.5)\n",
    "        elif line.upper() in section_titles:\n",
    "            para = doc.add_paragraph()\n",
    "            run = para.add_run(line.upper())\n",
    "            run.bold = True\n",
    "            run.font.size = Pt(12)\n",
    "            doc.add_paragraph().add_run(\"‚Äï\" * 80)\n",
    "        elif line.startswith(\"- \"):\n",
    "            para = doc.add_paragraph(style='List Bullet')\n",
    "            run = para.add_run(line[2:])\n",
    "            run.font.size = Pt(11)\n",
    "        elif line == \"\":\n",
    "            doc.add_paragraph()\n",
    "        else:\n",
    "            para = doc.add_paragraph()\n",
    "            run = para.add_run(line)\n",
    "            run.font.size = Pt(11)\n",
    "\n",
    "    #doc.save(\"AI_Gen_Resume.docx\")\n",
    "    doc.save(\"/kaggle/working/AI_Gen_Resume.docx\")\n",
    "\n",
    "    print(\"‚úÖ Resume saved as: AI_Gen_Resume.docx\")\n",
    "    return final_resume\n",
    "\n",
    "resume=generate_final_resume_agent.invoke({\"resume_text\": resume_text, \"jd_text\": jd_text, \"user_feedback\": feedback_list})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48c4276",
   "metadata": {
    "papermill": {
     "duration": 0.010791,
     "end_time": "2025-04-21T05:37:52.706322",
     "exception": false,
     "start_time": "2025-04-21T05:37:52.695531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Docx does not look very nicely formatted - so trying the tex file generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cf08f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:37:52.731563Z",
     "iopub.status.busy": "2025-04-21T05:37:52.730327Z",
     "iopub.status.idle": "2025-04-21T05:37:57.186394Z",
     "shell.execute_reply": "2025-04-21T05:37:57.185108Z"
    },
    "papermill": {
     "duration": 4.4707,
     "end_time": "2025-04-21T05:37:57.188350",
     "exception": false,
     "start_time": "2025-04-21T05:37:52.717650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved LaTeX resume to: /kaggle/working/AI_Gen_Resume.tex\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def generate_final_resume_tex_agent(resume_text: str, jd_text: str, user_feedback: list) -> str:\n",
    "    \"\"\"Uses Gemini and moderncv LaTeX to generate and save a styled .tex resume.\"\"\"\n",
    "\n",
    "    # Prepare feedback\n",
    "    feedback_text = \"\\n\".join([f\"{skill}: {detail}\" for skill, detail in user_feedback if detail])\n",
    "\n",
    "    # Gemini prompt\n",
    "    prompt = f\"\"\"\n",
    "You are a resume rewriting assistant. Given a resume, a job description, and user feedback about missing skills,\n",
    "generate a resume body that is well-structured and compact ‚Äî optimized for LaTeX formatting.\n",
    "\n",
    "Please use the following order:\n",
    "- Summary\n",
    "- Skills\n",
    "- Work Experience\n",
    "- Education\n",
    "- Projects (optional)\n",
    "- Leadership & Volunteering\n",
    "\n",
    "Just return clean plain text lines ‚Äî section titles, bullet points, no markdown.\n",
    "\n",
    "Resume:\n",
    "{resume_text}\n",
    "\n",
    "Job Description:\n",
    "{jd_text}\n",
    "\n",
    "User Feedback:\n",
    "{feedback_text}\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents= prompt)\n",
    "    resume_body = response.text.strip()\n",
    "\n",
    "    # Assemble moderncv template\n",
    "    tex_template = f\"\"\"\n",
    "\\\\documentclass[11pt,a4paper,sans]{{moderncv}}\n",
    "\\\\moderncvstyle{{classic}}\n",
    "\\\\moderncvcolor{{blue}}\n",
    "\n",
    "\\\\usepackage[utf8]{{inputenc}}\n",
    "\\\\usepackage[scale=0.75]{{geometry}}\n",
    "\\\\name{{Debisree}}{{Ray, PhD}}\n",
    "\\\\email{{debisreer@gmail.com}}\n",
    "\\\\phone{{662-694-1319}}\n",
    "\\\\social[linkedin]{{debisree-ray-ph-d-82241355}}\n",
    "\\\\social[kaggle]{{debisree}}\n",
    "\\\\social[github]{{debisree}}\n",
    "\n",
    "\\\\begin{{document}}\n",
    "\n",
    "\\\\makecvtitle\n",
    "\n",
    "\\\\section{{Resume}}\n",
    "{resume_body}\n",
    "\n",
    "\\\\end{{document}}\n",
    "\"\"\"\n",
    "\n",
    "    tex_path = \"/kaggle/working/AI_Gen_Resume.tex\"\n",
    "    with open(tex_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(tex_template)\n",
    "\n",
    "    print(f\"‚úÖ Saved LaTeX resume to: {tex_path}\")\n",
    "    return resume_body\n",
    "\n",
    "\n",
    "resume=generate_final_resume_tex_agent.invoke({\"resume_text\": resume_text, \"jd_text\": jd_text, \"user_feedback\": feedback_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c577ba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T05:37:57.214173Z",
     "iopub.status.busy": "2025-04-21T05:37:57.213245Z",
     "iopub.status.idle": "2025-04-21T05:38:02.001112Z",
     "shell.execute_reply": "2025-04-21T05:38:02.000111Z"
    },
    "papermill": {
     "duration": 4.802816,
     "end_time": "2025-04-21T05:38:02.002688",
     "exception": false,
     "start_time": "2025-04-21T05:37:57.199872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved LaTeX resume to: /kaggle/working/AI_Gen_Resume.tex\n"
     ]
    }
   ],
   "source": [
    "def sanitize_latex(text):\n",
    "    replacements = {\n",
    "        \"&\": r\"\\&\",\n",
    "        \"%\": r\"\\%\",\n",
    "        \"$\": r\"\\$\",\n",
    "        \"#\": r\"\\#\",\n",
    "        \"_\": r\"\\_\",\n",
    "        \"{\": r\"\\{\",\n",
    "        \"}\": r\"\\}\",\n",
    "        \"~\": r\"\\textasciitilde{}\",\n",
    "        \"^\": r\"\\textasciicircum{}\",\n",
    "        \"\\\\\": r\"\\textbackslash{}\"\n",
    "    }\n",
    "    for char, replacement in replacements.items():\n",
    "        text = text.replace(char, replacement)\n",
    "    return text\n",
    "\n",
    "@tool\n",
    "def generate_final_resume_tex_agent(resume_text: str, jd_text: str, user_feedback: list) -> str:\n",
    "    \"\"\"Uses Gemini and moderncv LaTeX to generate and save a styled .tex resume with LaTeX-safe formatting.\"\"\"\n",
    "\n",
    "    # Prepare feedback\n",
    "    feedback_text = \"\\n\".join([f\"{skill}: {detail}\" for skill, detail in user_feedback if detail])\n",
    "\n",
    "    # Gemini prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are a resume rewriting assistant. Given a resume, a job description, and user feedback about missing skills,\n",
    "    generate a resume body that is well-structured and compact ‚Äî optimized for LaTeX formatting.\n",
    "    \n",
    "    Please use the following order:\n",
    "    - Summary\n",
    "    - Skills\n",
    "    - Work Experience\n",
    "    - Education\n",
    "    - Projects (optional)\n",
    "    - Leadership and Volunteering\n",
    "    \n",
    "    Use plain text lines ‚Äî section titles, bullet points, no markdown or symbols.\n",
    "    \n",
    "    Resume:\n",
    "    {resume_text}\n",
    "    \n",
    "    Job Description:\n",
    "    {jd_text}\n",
    "    \n",
    "    User Feedback:\n",
    "    {feedback_text}\n",
    "    \"\"\"\n",
    "\n",
    "   \n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents= prompt)\n",
    "    resume_body = response.text.strip()\n",
    "    resume_body = sanitize_latex(resume_body)\n",
    "\n",
    "    # Build LaTeX using moderncv\n",
    "    tex_template = f\"\"\"\n",
    "\\\\documentclass[11pt,a4paper,sans]{{moderncv}}\n",
    "\\\\moderncvstyle{{classic}}\n",
    "\\\\moderncvcolor{{blue}}\n",
    "\n",
    "\\\\usepackage[utf8]{{inputenc}}\n",
    "\\\\usepackage[scale=0.75]{{geometry}}\n",
    "\\\\name{{Debisree}}{{Ray, PhD}}\n",
    "\\\\email{{debisreer@gmail.com}}\n",
    "\\\\phone{{662-694-1319}}\n",
    "\\\\social[linkedin]{{debisree-ray-ph-d-82241355}}\n",
    "\\\\social[kaggle]{{debisree}}\n",
    "\\\\social[github]{{debisree}}\n",
    "\n",
    "\\\\begin{{document}}\n",
    "\\\\makecvtitle\n",
    "\n",
    "\\\\section{{Resume}}\n",
    "{resume_body}\n",
    "\n",
    "\\\\end{{document}}\n",
    "\"\"\"\n",
    "\n",
    "    tex_path = \"/kaggle/working/AI_Gen_Resume.tex\"\n",
    "    with open(tex_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(tex_template)\n",
    "\n",
    "    print(f\"‚úÖ Saved LaTeX resume to: {tex_path}\")\n",
    "    return resume_body\n",
    "\n",
    "\n",
    "resume=generate_final_resume_tex_agent.invoke({\"resume_text\": resume_text, \"jd_text\": jd_text, \"user_feedback\": feedback_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fccb90a",
   "metadata": {
    "papermill": {
     "duration": 0.010678,
     "end_time": "2025-04-21T05:38:02.029267",
     "exception": false,
     "start_time": "2025-04-21T05:38:02.018589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### The tex file needs to run and needs a series of formatting improvement to look like a real resume! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedede39",
   "metadata": {
    "papermill": {
     "duration": 0.010467,
     "end_time": "2025-04-21T05:38:02.050552",
     "exception": false,
     "start_time": "2025-04-21T05:38:02.040085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### üôè Acknowledgments\n",
    "Special thanks to Kaggle and Google for providing the compute resources and access to cutting-edge tools like Gemini. This capstone project wouldn‚Äôt have been possible without the platform support and generous APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affa7102",
   "metadata": {
    "papermill": {
     "duration": 0.01122,
     "end_time": "2025-04-21T05:38:02.072358",
     "exception": false,
     "start_time": "2025-04-21T05:38:02.061138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7185796,
     "sourceId": 11466765,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 129.407065,
   "end_time": "2025-04-21T05:38:05.585151",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-21T05:35:56.178086",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
